# ğŸ¤– AI Virtual Mouse â€“ Edunet AI Azure Internship Project

## ğŸ“š Internship Overview: AI Azure by Edunet Foundation

This project was developed as part of the **AI Azure Internship** offered by **Edunet Foundation** in collaboration with **Microsoft** and **AICTE**.

### ğŸ¯ Internship Highlights:

* Delivered over **4 weeks** covering the following:

  * Week 1: AI, ML, DL basics + Microsoft Learn LMS setup
  * Week 2: Supervised & Unsupervised Learning (Regression & Classification)
  * Week 3: Generative AI, Azure Custom Vision hands-on
  * Week 4: Neural Networks, Deep Learning, and Final Project
* Mentorship-driven sessions
* Project-based learning with real-world applications

---

## ğŸ–±ï¸ Project Title: AI Virtual Mouse

### ğŸ’¡ Objective:

To build an **AI-powered virtual mouse** that enables users to control the system cursor using **hand gestures** tracked by a webcam.

---

## âš™ï¸ Technologies Used

* Python
* OpenCV
* MediaPipe
* PyAutoGUI
* Win32 API (for window control)
* NumPy

---

## ğŸ§  Features

| Feature                       | Description                                                             |
| ----------------------------- | ----------------------------------------------------------------------- |
| ğŸ– Hand Tracking              | Uses MediaPipe to detect and track hand landmarks in real-time          |
| ğŸ–±ï¸ Cursor Movement           | Index finger controls mouse movement via screen-mapped hand coordinates |
| ğŸ‘† Click Gesture              | Clicking by bringing index and middle fingers close                     |
| ğŸ–±ï¸ Scroll Control            | Two-finger scroll gesture (up/down)                                     |
| âœŠ Drag and Drop               | Thumb + index finger pinch-and-hold for drag actions                    |
| ğŸªŸ Maximize/Minimize Window   | Gesture-based window maximize/minimize using pinch gap detection        |
| ğŸšï¸ Volume Mute + Edge Launch | Special gesture triggers volume mute and opens Microsoft Edge browser   |

---

## ğŸ“ File Structure

```
â”œâ”€â”€ main.py               # Main script to run the AI Virtual Mouse
â”œâ”€â”€ HandTrackingModule.py # Custom hand tracking module using MediaPipe
â”œâ”€â”€ README.md             # Project documentation
```

---

## ğŸš€ How It Works

1. Open a webcam stream using OpenCV.
2. Use MediaPipe to detect hand landmarks.
3. Map fingertip coordinates to screen resolution.
4. Perform real-time actions:

   * Move cursor with index finger
   * Left click by pinching index & middle fingers
   * Scroll by moving hand with two fingers up
   * Drag using thumb + index
   * Maximize/Minimize windows by adjusting pinch gap
   * Trigger volume mute + Edge browser with 3-finger gesture

---

## ğŸ§ª How to Run

1. Ensure required libraries are installed:

   ```bash
   pip install opencv-python mediapipe pyautogui pywin32 numpy
   ```
2. Run the project:

   ```bash
   python main.py
   ```

---
[Watch the Demo video](demo.mp4)
## ğŸ“ Developed As Part Of

**AI Azure Internship â€“ May 2025**
**Edunet Foundation** | Microsoft | AICTE
Intern: *Sampathirao Sai Rohan*
Institution: *JNTUK University College of Engineering, Vizianagaram*
Student ID: `STU680bcbf1e6a941745603569`
Internship ID: `INTERNSHIP_174365314467ee0918e7994`

---

## ğŸ”— Useful Links

* [Edunet Foundation](http://www.edunetfoundation.org/)
* [Microsoft Learn](https://learn.microsoft.com/)
* [MediaPipe Documentation](https://developers.google.com/mediapipe)
* [PyAutoGUI Docs](https://pyautogui.readthedocs.io/)

---

> ğŸ‰ Proud to be a part of this exciting journey in AI Azure
